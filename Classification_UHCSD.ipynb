{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attractive-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b592a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "greek-buffer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 383 images belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Network': 0, 'Pearlite_Spheroidite': 1, 'Martensite': 2, 'Pearlite': 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "                                  \n",
    "train_set = train_datagen.flow_from_directory('/Users/saswa/Documents/Joyita_2023/MDXp_content/Tutorail4_UHCSD/UHCSD_ML/Data_steel/Train_set/', \n",
    "                                               class_mode='categorical',\n",
    "                                               classes = ['Network','Pearlite_Spheroidite','Martensite', 'Pearlite'],\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 color_mode ='grayscale')\n",
    "train_set.class_indices\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intense-presence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('/Users/saswa/Documents/Joyita_2023/MDXp_content/Tutorail4_UHCSD/UHCSD_ML/Data_steel/Test_set/',class_mode='categorical',\n",
    "                                            classes = ['Network','Pearlite_Spheroidite','Martensite', 'Pearlite'],\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32, color_mode ='grayscale')\n",
    "\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worldwide-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suspended-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters = 64, kernel_size =3, activation = 'relu', input_shape = [64, 64,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "honest-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "generous-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blocked-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "antique-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units = 128, activation ='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lonely-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opened-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "religious-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "                loss=loss_fn,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "anticipated-johnson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,643,844\n",
      "Trainable params: 1,643,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "destroyed-worthy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 8s 566ms/step - loss: 1.3360 - accuracy: 0.4648 - val_loss: 1.2511 - val_accuracy: 0.4216\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 2s 197ms/step - loss: 1.1210 - accuracy: 0.5013 - val_loss: 1.1477 - val_accuracy: 0.4510\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 2s 169ms/step - loss: 1.0632 - accuracy: 0.5379 - val_loss: 1.2203 - val_accuracy: 0.4804\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.0377 - accuracy: 0.5483 - val_loss: 1.1297 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 0.9564 - accuracy: 0.5849 - val_loss: 1.1408 - val_accuracy: 0.4510\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 0.8752 - accuracy: 0.6501 - val_loss: 1.1001 - val_accuracy: 0.5098\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.8398 - accuracy: 0.6919 - val_loss: 1.0288 - val_accuracy: 0.4804\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.7924 - accuracy: 0.7285 - val_loss: 0.9982 - val_accuracy: 0.5098\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 2s 171ms/step - loss: 0.7071 - accuracy: 0.7467 - val_loss: 1.1161 - val_accuracy: 0.5490\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5856 - accuracy: 0.8120 - val_loss: 1.2689 - val_accuracy: 0.5392\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5031 - accuracy: 0.8538 - val_loss: 1.3010 - val_accuracy: 0.5294\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.4331 - accuracy: 0.8773 - val_loss: 1.3814 - val_accuracy: 0.6275\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 0.3524 - accuracy: 0.9138 - val_loss: 1.1572 - val_accuracy: 0.6176\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.2691 - accuracy: 0.9191 - val_loss: 1.1806 - val_accuracy: 0.6176\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.2196 - accuracy: 0.9556 - val_loss: 1.1092 - val_accuracy: 0.6373\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.1553 - accuracy: 0.9739 - val_loss: 1.4785 - val_accuracy: 0.5490\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.1246 - accuracy: 0.9739 - val_loss: 1.2914 - val_accuracy: 0.6078\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.0909 - accuracy: 0.9817 - val_loss: 1.3437 - val_accuracy: 0.6176\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 0.0668 - accuracy: 0.9948 - val_loss: 1.2970 - val_accuracy: 0.6176\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.0542 - accuracy: 0.9948 - val_loss: 1.3030 - val_accuracy: 0.6373\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.0471 - accuracy: 0.9948 - val_loss: 1.3960 - val_accuracy: 0.6569\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.0485 - accuracy: 0.9948 - val_loss: 1.4118 - val_accuracy: 0.6569\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.0331 - accuracy: 0.9974 - val_loss: 1.8768 - val_accuracy: 0.6569\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.0297 - accuracy: 0.9974 - val_loss: 1.4452 - val_accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.0212 - accuracy: 0.9974 - val_loss: 1.2947 - val_accuracy: 0.6373\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 2s 123ms/step - loss: 0.0171 - accuracy: 0.9974 - val_loss: 1.7843 - val_accuracy: 0.6569\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 1.5953 - val_accuracy: 0.6471\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.8058 - val_accuracy: 0.6176\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 1.7211 - val_accuracy: 0.6471\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.7474 - val_accuracy: 0.6471\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 2s 124ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6980 - val_accuracy: 0.6569\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 2s 123ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.8591 - val_accuracy: 0.6373\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 2s 169ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7689 - val_accuracy: 0.6373\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.8435 - val_accuracy: 0.6471\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.7996 - val_accuracy: 0.6373\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8851 - val_accuracy: 0.6373\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8478 - val_accuracy: 0.6471\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9048 - val_accuracy: 0.6373\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9382 - val_accuracy: 0.6569\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.8520 - val_accuracy: 0.6471\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0066 - val_accuracy: 0.6373\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9022 - val_accuracy: 0.6471\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9572 - val_accuracy: 0.6373\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.9705 - val_accuracy: 0.6471\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.9667 - val_accuracy: 0.6373\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0215 - val_accuracy: 0.6471\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9998 - val_accuracy: 0.6471\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0160 - val_accuracy: 0.6373\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0330 - val_accuracy: 0.6471\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0100 - val_accuracy: 0.6471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d50273130>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = train_set, validation_data = test_set, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stupid-plasma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n",
      "[[1 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Network': 0, 'Pearlite_Spheroidite': 1, 'Martensite': 2, 'Pearlite': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "#from tensorflow.keras.utils import load_img\n",
    "#from tensorflow.keras.utils import img_to_array\n",
    "test_image = load_img('/Users/saswa/Documents/Joyita_2023/MDXp_content/Tutorail4_UHCSD/UHCSD_ML/Data_steel/single_prediction/net.tif', target_size = (64, 64),color_mode = 'grayscale')\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)                  \n",
    "result = (cnn.predict(test_image) > 0.3).astype('int')\n",
    "print(result)\n",
    "train_set.class_indices\n",
    "\n",
    "# >0.3 is the decision threshold of prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
